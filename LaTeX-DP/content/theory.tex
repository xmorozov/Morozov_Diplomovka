\chapter{Theory}
\section{Furuta's Pendulum}
Rotational inverted pendulum or Furuta’s pendulum was firstly invented in 1992 at the Tokyo Institute of Technology by Katsuhisa Furuta as an example of a complex nonlinear oscillator in the sake of control algorithms testing in process control theory.
The pendulum composes of two main parts: motor-driven arm, which rotates in the horizontal plane and a pendulum, attached to that arm, which freely rotates in the vertical plane. The system is underactuated and extremely nonlinear due to the gravitational forces and the coupling arising from the Coriolis and centripetal forces. The schematic representation of the pendulum is shown in \ref{furuta}
\begin{figure}[h]
	\centering
	\includegraphics[width=.6\linewidth]{images/furuta}
	\caption{Furuta's Pendulum}
	\label{furuta}
\end{figure}
\newpage
The symbols in the figure indicate the following:
\begin{itemize}
	\item \textbf{$g$} - gravitational acceleration [\si{\metre\per\square\second}]
	\item \textbf{$m_0$} - mass of arm [\si{\kilogram}]
	\item \textbf{$m_1$} - mass of pendulum [\si{\kilogram}]
	\item \textbf{$L_0$} - length of arm [\si{\metre}]
	\item \textbf{$L_1$} - length of pendulum [\si{\metre}]
	\item \textbf{$l_1$} - location of the pendulums center of mass [\si{\metre}]
	\item \textbf{$I_0$} - moment of inertia of arm [\si{\kilogram\per\square\metre}]
	\item \textbf{$I_1$} - moment of inertia of pendulum [\si{\kilogram\per\square\metre}]
	\item \textbf{$\theta_0$} - arm angle [\si{\radian}]
	\item \textbf{$\theta_1$} - pendulum angle [\si{\radian}]
	\item \textbf{$\tau$} - motor torque [\si{\volt}]
\end{itemize}
\subsection{Mathematical Model of the Pendulum}
To design a predictive controller, the knowledge of the dynamic model of the process is necessary. For that purpose, we found the discrete-time state-space representation the most suitable.
To obtain the state representation of the process the state variables must be defined first:
\begin{equation}
\begin{bmatrix}
x_1(t) & x_2(t) & x_3(t) & x_4(t)
\end{bmatrix}^\intercal = 
\begin{bmatrix}
\theta_0(t) & \dot{\theta}_0(t) & \theta_1(t) & \dot{\theta}_1(t)
\end{bmatrix}^\intercal
\end{equation}
And the control variable:
\begin{equation} u(t) = \tau(t) \end{equation}
The analytical model is based on the equations of motion derived from the Lagrange equations \cite{furuta:pendulum}, which represent the most commonly used method for establishing equations of motion of difficult mechanical systems. This method is applied for obtaining mathematical models of eg manipulators, with several degreases of freedom. Taking into account damping in the
form of friction, the resulting equations of motion of the
pendulum are 
\begin{subequations}
	\begin{align}
	\ddot{\theta}_0 &= \frac{\gamma(\epsilon\dot{\theta}_0^2+\rho)-\delta(\tau+\beta\dot{\theta}_1^2-\sigma\dot{\theta}_0\dot{\theta}_1)}{\gamma^2-\alpha\delta}\\
	\ddot{\theta}_1 &= \frac{\gamma(\tau+\beta\dot{\theta}_1^2-\sigma\dot{\theta}_0\dot{\theta}_1)-\alpha(\epsilon\dot{\theta}_0^2+\rho)}{\gamma^2-\alpha\delta}
	\end{align}
\end{subequations}
where
\begin{subequations}
	\begin{align}
	\alpha &= I_0+L_0^2m_1+l_1^2m_1\sin^2\theta_1\\
	\beta &= L_0m_1l_1\sin\theta_1 \\
	\gamma &= L_0m_1l_1\cos\theta_1\\
	\delta &= I_1+l_1^2m_1\\
	\epsilon &= l^2_1m_1\sin\theta_1\cos\theta_1\\
	\rho &= m_1gl_1\sin\theta_1\\
	\tau &= 2l^2_1m_1\sin\theta_1\cos\theta_1
	\end{align}
\end{subequations}
These equations are further utilized to establish the state
space model
\begin{subequations}
	\begin{align}
	\dot{x_1} &= \dot{\theta_0} \\
	\dot{x_2} &= \frac{\gamma(\epsilon\dot{\theta_0}^2+\rho)-\delta(\tau+\beta\dot{\theta_1}^2-\sigma\dot{\theta_0}\dot{\theta_1})}{\gamma^2-\alpha\delta}\\
	\dot{x_3} &= \dot{\theta_1}\\
	\dot{x_4} &= \frac{\gamma(\tau+\beta\dot{\theta_1}^2-\sigma\dot{\theta_0}\dot{\theta_1})-\alpha(\epsilon\dot{\theta_0}^2+\rho)}{\gamma^2-\alpha\delta}
	\end{align}
\end{subequations}
Now these non-linear differential equations could be written in the form of matrices:
\begin{equation}\label{nonlinmodel}
\begin{bmatrix}
\dot{x}_1(t) \\ \dot{x}_2(t) \\ \dot{x}_3(t) \\ \dot{x}_4(t)
\end{bmatrix} = \begin{bmatrix}
\dot{\theta}_0\\
\frac{\gamma(\epsilon\dot{\theta}_0^2+\rho)-\delta(\tau+\beta\dot{\theta}_1^2-\sigma\dot{\theta}_0\dot{\theta}_1)}{\gamma^2-\alpha\delta}\\
\dot{\theta}_1\\
\frac{\gamma(\tau+\beta\dot{\theta}_1^2-\sigma\dot{\theta}_0\dot{\theta}_1)-\alpha(\epsilon\dot{\theta}_0^2+\rho)}{\gamma^2-\alpha\delta}
\end{bmatrix}
\end{equation}
As we can see the derivatives of the states are the functions of the current states and control input. And more importantly, those variables have nonlinear interactions within each dynamic equation. 
\begin{equation}\begin{bmatrix}
\dot{x}_1(t) \\ \dot{x}_2(t) \\ \dot{x}_3(t) \\ \dot{x}_4(t)
\end{bmatrix} = f(x(t),u(t)) =\begin{bmatrix}f_1(x(t),u(t))\\f_2(x(t),u(t))\\f_3(x(t),u(t))\\f_4(x(t),u(t))\end{bmatrix} \end{equation}
So that’s our non-linear dynamic model of the process. But only the NMPC controller is able to operate with such a model. So, to make that model suitable for LQR and MPC controller we can approximate that non-linear model by a linear, time-invariant state-space model as follows:
\begin{equation}\dot{x}(t) = Ax(t) + Bu(t)\end{equation}
And the constant matrices are derived as:
\begin{subequations}
	\begin{align}
	A &= \begin{bmatrix}
	\frac{\partial f_1(x(t),u(t))}{\partial x_1}&\frac{\partial f_1(x(t),u(t))}{\partial x_2}&\frac{\partial f_1(x(t),u(t))}{\partial x_3}&\frac{\partial f_1(x(t),u(t))}{\partial x_4}\\
	\frac{\partial f_2(x(t),u(t))}{\partial x_1}&\frac{\partial f_2(x(t),u(t))}{\partial x_2}&\frac{\partial f_2(x(t),u(t))}{\partial x_3}&\frac{\partial f_2(x(t),u(t))}{\partial x_4}\\
	\frac{\partial f_3(x(t),u(t))}{\partial x_1}&\frac{\partial f_3(x(t),u(t))}{\partial x_2}&\frac{\partial f_3(x(t),u(t))}{\partial x_3}&\frac{\partial f_3(x(t),u(t))}{\partial x_4}\\
	\frac{\partial f_4(x(t),u(t))}{\partial x_1}&\frac{\partial f_4(x(t),u(t))}{\partial x_2}&\frac{\partial f_4(x(t),u(t))}{\partial x_3}&\frac{\partial f_4(x(t),u(t))}{\partial x_4}
	\end{bmatrix}\\ 
	B &= \begin{bmatrix}
	\frac{\partial f_1(x(t),u(t))}{\partial u}\\\frac{\partial f_2(x(t),u(t))}{\partial u}\\\frac{\partial f_3(x(t),u(t))}{\partial u}\\\frac{\partial f_4(x(t),u(t))}{\partial u}
	\end{bmatrix}
	\end{align}
\end{subequations}
And when we compute these derivatives, we obtain a linearized continuous-time dynamic model of the pendulum in the form of state matrices
\begin{subequations}\label{linmatrices}
	\begin{align}
	A &=\begin{bmatrix}0&1&0&0\\
	0&0&\frac{-gL_0l_1^2m_1^2}{(m_1L_0^2+I_0)(m_1l_1^2+I_1)-L_0^2l_1^2m_1^2}&0\\
	0&0&0&1\\
	0&0&\frac{gl_1m_1(m_1L_0^2+I_0)}{(m_1L_0^2+I_0)(m_1l_1^2+I_1)-L_0^2l_1^2m_1^2}&0
	\end{bmatrix}\\
	B &=	\begin{bmatrix}
	0\\ 
	\frac{m_1L_1^2+I_1}{(m_1L_0^2+I_0)(m_1l_1^2+I_1)-L_0^2l_1^2m_1^2}\\
	0\\
	\frac{-L_0l_1m_1}{(m_1L_0^2+I_0)(m_1l_1^2+I_1)-L_0^2l_1^2m_1^2}
	\end{bmatrix}\\
	C &= \begin{bmatrix}0&0&1&0\end{bmatrix}\\
	D &= 0
	\end{align}
\end{subequations}
Now those linearized equations of motion would be evaluated at two equilibrium positions: upright and downward. The reason is that at the downward position the system's output, which is the position of the pendulum, has a stable point at “$+\pi$” and “$-\pi$”, while at the upright position system has no stable point.

The model, obtained by linearization around the upright operation point, is used for fulfilling the main control objective, which is stabilizing the pendulum at the upright position. The second model is used to simulate process behavior during initial excitation by a Swing-up controller.
\section{Controller Theory}
In this section theory for the individual controllers is described. As we are aiming for swing-up control of the pendulum, several controllers should be designed. For the heuristic swing-up approach an energy shaping controller and a predictive controller. And for the optimal swing-up approach a nonlinear model predictive control strategy.
\subsection{Model Predictive Control}
MPC uses a model of the system to make predictions about the system’s future behavior. MPC solves an online optimization algorithm to find the optimal control action that drives the predicted output to the reference. MPC can handle MIMO systems that may have interactions between their inputs and outputs. It can also handle input and output constraints. MPC has preview capability; it can incorporate future reference information into the control problem to improve controller performance. Due to all these properties MPC provides the highest quality of control performance at the moment.
\subsubsection{MPC formulation}
The model predictive control requires the linear discrete-time state-space model of the process
\begin{subequations}\label{linmodel}
	\begin{align}	
	x_{k+1} = Ax_k + Bu_k\\
	y_k = Cx_k + Du_k
	\end{align}
\end{subequations}
Thanks to the knowledge of that model, we can predict the evolution of states and outputs of the system.\\
Due to the setup of the controlled process, the MPC should be formulated to regulate the states of the system to the origin. And such MPC can be formulated as
\begin{subequations}\label{mpcgeneral}
	\begin{align}
		\min_{U} \sum_{k=0}^{N-1}& \lrp{\left\| \ui{Q}{x}x_{k}\right\|_p+\left\|\ui{Q}{u}u_{k}\right\|_p}\\
	    \label{eq217b}s.t.\qquad&x_{k+1} = Ax_{k} + Bu_{k}\qquad\quad  k \in \mathbb{N}_0^{N-1}\\
		&x_0 = x(t)\\
		\label{cst_x}&x_{k}\in\mathcal{X}\qquad\qquad\qquad\qquad\,  k \in \mathbb{N}_0^{N-1}\\
		\label{cst_u}&u_{k}\in\mathcal{U}\qquad\qquad\qquad\qquad\;   k \in \mathbb{N}_0^{N-1}
	\end{align}
\end{subequations}
where $\mathcal{X}$ and $\mathcal{U}$ are polytopic state and input constraints respectively and defined as
\begin{subequations}
	\begin{align}
	\mathcal{X} &= \{\ui{H}{x}x_k\leq \ui{K}{x}\}\\
	\mathcal{U} &= \{\ui{H}{u}u_k\leq \ui{K}{u}\}
	\end{align}
\end{subequations}
Unfortunately, such formulation is inappropriate for quadratic programming solver, so it has to be reformulated in the form of a quadratic optimization problem.
\subsubsection{MPC as a QP optimization problem}
The QP optimization problem has the following form
\begin{subequations}
	\begin{align}
	\min_{z} & z^\intercal Pz + 2Q^\intercal z + R\\
	\label{cst_qp}s.t.\quad&Hz\leq G\\
	&\ui{H}{eq}z = \ui{G}{eq}
	\end{align}
\end{subequations}
As the first step, the standard MPC cost function should be written in a vector form
\begin{equation}
	\min_{U} X^\intercal\ui{\tilde{Q}}{x}X + U^\intercal\ui{\tilde{Q}}{u}\,U\\
\end{equation}
where $X$ is a vector of predicted states, $U$ is an optimal trajectory of future control inputs and $\ui{\tilde{Q}}{x}$ and $\ui{\tilde{Q}}{u}$ are the matrices of original weight matrices.
\begin{equation}
	X = \begin{bmatrix}
	x_k\\x_{k+1}\\\vdots\\x_{k+N-1}
		\end{bmatrix}
\end{equation}
\begin{equation}
U = \begin{bmatrix}
u_k\\u_{k+1}\\\vdots\\u_{k+N-1}
\end{bmatrix}
\end{equation}
\begin{equation}
\ui{\tilde{Q}}{x} = \begin{bmatrix}
\ui{Q}{x}&0&\cdots&0\\
0&\ui{Q}{x}&\cdots&0\\
\vdots&\vdots&\ddots&\vdots\\
0&0&\cdots&\ui{Q}{x}
\end{bmatrix}
\end{equation}
\begin{equation}
\ui{\tilde{Q}}{u} = \begin{bmatrix}
\ui{Q}{u}&0&\cdots&0\\
0&\ui{Q}{u}&\cdots&0\\
\vdots&\vdots&\ddots&\vdots\\
0&0&\cdots&\ui{Q}{u}
\end{bmatrix}
\end{equation}
At the next step, the equality constrains (\ref{eq217b}) should be expressed in the vector form. We can achieve that by predicting the evolution of states over the whole prediction horizon.
\begin{equation}
\begin{split}
x_0 &= x(t)\\
\hat{x}_{1} &= Ax_0 + Bu_0\\
\hat{x}_{2} &= A\hat{x}_{1} + Bu_{1}\\
&= A^2x_0 + ABu_0 + Bu_{1}\\
\hat{x}_{3} &= A\hat{x}_{2} + Bu_{2}\\
&= A^3x_0 + A^2Bu_0 + ABu_{1} + Bu_{2}\\
&\vdots\\
\hat{x}_{N} &= A^Nx_0+\sum_{j=0}^{N-1}A^jBu_{N-j-1}
\end{split}
\end{equation}
Or, if we write these equations in a compact form, we obtain
\begin{equation}
	\begin{bmatrix}
	x_0\\\hat{x}_{1}\\ \hat{x}_{2}\\\vdots\\ \hat{x}_{N-1}
	\end{bmatrix} = 
	\begin{bmatrix}I\\A\\A^2\\ \vdots \\ A^{N-1}\end{bmatrix}x_0 + 
	\begin{bmatrix}
	0& 0&\cdots&0&0\\
	B&0&\cdots&0&0\\
	AB&B&\cdots&0&0\\
	\vdots&\vdots&\ddots&\vdots&\vdots\\
	A^{N-2}B&A^{N-3}B&\cdots&B&0\end{bmatrix}
	\begin{bmatrix}u_0\\u_{1}\\u_{2}\\\vdots\\u_{N-1}\end{bmatrix}
\end{equation}
Or in the short form
\begin{equation}\label{eq227}
	X = \tilde{A}x_0 + \tilde{B}U
\end{equation}
At this point, we can substitute as $X$ in the cost function by (\ref{eq227}). Then we obtain the new objective function
\begin{equation}\label{eq228}
	\min_{U} (\tilde{A}x_0 + \tilde{B}U)^\intercal\ui{\tilde{Q}}{x}(\tilde{A}x_0 + \tilde{B}U) + U^\intercal\ui{\tilde{Q}}{u}\,U\\
\end{equation}
And when we expand and simplfie (\ref{eq228}), we obtain
\begin{equation}
	U^\intercal(\tilde{B}^\intercal\ui{\tilde{Q}}{x}\tilde{B} + \ui{\tilde{Q}}{u})U + 2x_0^\intercal\tilde{A}^\intercal\ui{\tilde{Q}}{x}\tilde{B}U + x_0^\intercal\tilde{A}\ui{\tilde{Q}}{x}\tilde{A}x_0
\end{equation}
Now if we define $z = U$, we can cleary see matrices $P$, $Q$ and $R$, which occurs in a standart cost function for the quadratic optimization.
\begin{subequations}
	\begin{align}
		P &= \tilde{B}^\intercal\ui{\tilde{Q}}{x}\tilde{B} + \ui{\tilde{Q}}{u}\\
		Q &= (2x_0^\intercal\tilde{A}^\intercal\ui{\tilde{Q}}{x}\tilde{B}U)^\intercal\\
		R &= x_0^\intercal\tilde{A}\ui{\tilde{Q}}{x}\tilde{A}x_0
	\end{align}
\end{subequations}
Now only constrains remain. Constrains (\ref{cst_x}) and (\ref{cst_u}) must be reformulated as (\ref{cst_qp}). Those constrains we consider as a upper and lower bounds for the states and control inputs respectively
\begin{subequations}
	\begin{align}
		\ui{x}{min} &\leq x_k \leq \ui{x}{max} \quad k \in \mathbb{N}_0^{N-1}\\
		\ui{u}{min} &\leq u_k \leq \ui{u}{max} \quad k \in \mathbb{N}_0^{N-1}
	\end{align}
\end{subequations}
Now we split and vectorise those constrains
\begin{subequations}
\begin{align}
	X &\leq \ \; \, \ui{X}{max}\\
	-X &\leq -\ui{X}{min}\\
	U &\leq \ \; \, \ui{U}{max}\\
	-U &\leq -\ui{U}{min}
\end{align}
\end{subequations}
In the next step, we substitute $X$ in the states constrains by a (\ref{eq227}) and express $U$
\begin{subequations}
	\begin{align}
	\tilde{B}\,U &\leq \ \; \,\ui{X}{max} - \tilde{A}x_0\\
	-\tilde{B}\,U &\leq -\ui{X}{min} + \tilde{A}x_0\\
	U &\leq \ \; \,\ui{U}{max}\\
	-U &\leq -\ui{U}{min}
	\end{align}
\end{subequations}
Those constraints are in the standard form and by combining them, we obtain matrices of inequality constraints $H$ and $G$ for the quadratic programming problem
\begin{equation}
	H = \begin{bmatrix}
	\ \; \,\tilde{B}\\
	-\tilde{B}\\
	\ \ \, I\\
	-I\\
	\end{bmatrix}, \quad
	G = \begin{bmatrix}
	\ \; \,\ui{X}{max} - \tilde{A}x_0\\
	-\ui{X}{min} + \tilde{A}x_0\\
	\ \ \:\ui{U}{max}\\
	-\ui{U}{min}
	\end{bmatrix}
\end{equation}
At this point, as matrices $R$, $Q$, $R$, $H$ and $G$ are defined, we can implement MPC by using any quadratic programming solver.
\subsection{Energy Shaping Controller}
For the initial excitation of the system, we use the energy-based swing-up controller. The strategy with this controller is that we increase the amplitude of swings by increasing the energy of the system with every swing. The energy is added by controlling arms movements and depends on the actual energy of the pendulum. The actual energy of the pendulum can be calculated from the actual position of the pendulum and its velocity: 
\begin{equation}
E = \frac{m_1gl_1}{2}\lrp{\lrp{\frac{\dot{\theta_1}}{\omega_0}}^2+\cos\theta_1 - 1}
\end{equation}
Than the control law has following form:
\begin{equation}\label{energy-shaping}
	u = \ui{k}{v}E\,\mathrm{sign}\lrp{\dot{\theta_1}\cos\theta_1}
\end{equation}
Where element $\mathrm{sign}\lrp{\dot{\theta_1}\cos\theta_1}$ determines direction i which the force will be applied and $\ui{k}{v}E$ is the gain of the controller.
\newpage
\subsection{Nonlinear Model Predictive Control}
In general to predict bechavior of the process MPC uses a linear predictive model (\ref{linmodel}). But the original dynamic model of Furuta pendulum is nonlinear (\ref{nonlinmodel}) and its linearized version precisly describes process dynamic only in some range around linearisation point. So linear MPC could be designed to only control the process in that range. And as the main task of the thesis is to perform the swing-up control with one controller. In that case a nonlinear model (\ref{nonlinmodel}) has to be used as a prediction model and Nonlinear Model predictive Controller has to be designed.

To design an optimal controller, an optimization problem has to be solved. In case of NMPC a Nonlinear Programing (NLP) problem is solved
\begin{subequations}\label{nlpgeneral}
	\begin{align}
	\min_{x}\  &f(x)\\
	s.t.\  &h(x) = 0\\
		 &g(x)\leq 0
	\end{align}
\end{subequations}
Sometimes, to obtain an analytical solution to such problem, could be extremely difficult. So a numerical method called Sequential Quatratic Programming (SQP) is used instead.
\subsubsection{Sequential Quatratic Programming}
Sequential Quadratic Programming is arguably become the most successful method for solving nonlinearly constrained optimization problems \cite{SQP:Theory}. Its general idea is to approximate NLP at current iterate by QP subproblem, solve that subproblem, than use the solution to construct a new iterate. This construction is done in such a way that the sequence converges to a local minimum of the NLP.

The main condition for a QP subproblem is that it has to reflect the properties of NLP at current iteration. But before such subproblem could be constructed, a few terms should be establish first.
\begin{itemize}
	\item Lagrangian functional of the NLP, $\mathcal{L}$ is defined as\begin{equation}
		\mathcal{L}(x,\lambda,\mu) = f(x) + \lambda^\intercal h(x) + \mu^\intercal g(x) 
	\end{equation}
	\item The gradient of $f$, $\nabla f(x)$ is denoted as
	\begin{equation}
		\nabla f(x) = \lrp{\diff{f(x)}{x_1},\diff{f(x)}{x_2},\cdots,\diff{f(x)}{x_n}}^\intercal
	\end{equation}
	\item Hessian of f, $Hf(x)$ is the matrix of second partial derivatives as given by
	\begin{equation}
		\lrp{Hf(x)}_{ij} := \diffxy{f(x)}{x_i}{x_j}
	\end{equation}
\end{itemize}
A major concern in SQP method is the choice of appropriate quadratic subproblem. 
The most obvious choice for the objective functional in this quadratic program is its local quadratic approximation
\begin{equation}
f(x)\approx f(x_k)+\nabla f(x_k)\lrp{x-x_k}+\frac{1}{2}\lrp{x-x_k}^\intercal Hf(x_k)\lrp{x-x_k}
\end{equation}
and the constraint functions $h$ and $g$ by their local affine approximations
\begin{subequations}
	\begin{align}
		h(x)&\approx h(x_k)+\nabla h(x_k)\lrp{x-x_k}\\
		g(x)&\approx g(x_k)+\nabla g(x_k)\lrp{x-x_k}	
	\end{align}
\end{subequations}
And after setting 
\begin{subequations}
	\begin{align}
		d_x:=x-x_k\\
		B_k = hf(x_k)
	\end{align}
\end{subequations}
The following form of the QP subproblem is accured
\begin{subequations}
	\begin{align}
		\min_{d_x}\  &\nabla f(x_k)^\intercal d_x+\frac{1}{2}d_x^\intercal B_k d_x\\
		s.t.\  &h(x_k)+\nabla h(x_k)\lrp{x-x_k} = 0\\
		&g(x_k)+\nabla g(x_k)\lrp{x-x_k}\leq 0
	\end{align}
\end{subequations}
This is a reasonable approximation in case of linear constraints. In case of nonlinear constraints makes such choice inappropriated. 

To take nonlinearities in the constraints into account a quadratic model of the Lagrangian function could be used as the obective instead.
\begin{subequations}
	\begin{align}
	\min_{x}\  & \mathcal{L}(x,\lambda^*,\mu^*)\\
	s.t.\  &h(x)= 0\\
	&g(x)\leq 0
	\end{align}
\end{subequations}
Although the optimal multipliers are unknown, then approximations $\lambda_k$,$\mu_k$ could be contained as part of the iterative process. Then at a current iterate $(x_k,\lambda_k,\mu_k)$, the objective functional in stems from the quadratic Taylor series approximation.
\begin{equation}
	\mathcal{L}(x_k,\lambda_k,\mu_k)+\nabla\mathcal{L}(x_k,\lambda_k,\mu_k)^\intercal d(x)+\frac{1}{2}d(x)^\intercal H\mathcal{L}(x_k,\lambda_k,\mu_k) d(x)
\end{equation}
What leads to the final QP subproblem
\begin{subequations}
	\begin{align}
	\min_{d_x}\  &\nabla \mathcal{L}(x_k,\lambda_k,\mu_k)^\intercal d_x+\frac{1}{2}d_x^\intercal H\mathcal{L}(x_k,\lambda_k,\mu_k)d_x\\
	s.t.\  &h(x_k)+\nabla h(x_k)\lrp{x-x_k} = 0\\
	&g(x_k)+\nabla g(x_k)\lrp{x-x_k}\leq 0
	\end{align}
\end{subequations}
By solving that QP subproblem solution $d_x$ as well as local optimal values of multipliers $\lambda_{qp}$ and $\mu_{qp}$ are accuried, and setting 
\begin{subequations}
	\begin{align}
		d_\lambda &= \lambda_{qp}-\lambda_k\\
		d_\mu &= \mu_{qp}-\mu_k
	\end{align}
\end{subequations}
allow the updates of $(x,\lambda,\mu)$ to be written in the compact form
\begin{subequations}
	\begin{align}
	x_{k+1} &= x_k + \alpha d_x\\
	\lambda_{k+1} &= \lambda_k + \alpha d_\lambda\\
	\mu_{k+1} &= \mu_k + \alpha d_\mu
	\end{align}
\end{subequations}
for some selection of the steplength parameter $\alpha$. Once the new iterates are constructed, the problem functions and derivatives are evaluated and a
prescribed choice of $B_k$ can be calculated.

In summary the Basic SQP algorithm looks like this:
\begin{itemize}
	\item Inicializacia:\\
Given approximations $(x_0,\lambda_0,\mu_0)$, $B_0$ and a merit function $\phi$, set $k=0$
\item Loop:
\begin{enumerate}
	\item Form and solve QP subproblem to obtain $(d_x,d_\lambda,d_\mu)$.
	\item Choose steplength $\alpha$ so that
	\begin{equation}
		\phi(x_k + \alpha d_x)<\phi(x_k)
	\end{equation}
	\item Set
	\begin{subequations}
		\begin{align}
		x_{k+1} &= x_k + \alpha d_x\\
		\lambda_{k+1} &= \lambda_k + \alpha d_\lambda\\
		\mu_{k+1} &= \mu_k + \alpha d_\mu
		\end{align}
	\end{subequations}
	\item Stop if converged.
	\item Compute $B_{k+1}$.
	\item Set $k := k+1$; go to 1.
\end{enumerate}
\end{itemize}